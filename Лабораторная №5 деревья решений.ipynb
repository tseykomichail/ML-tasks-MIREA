{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3613a06",
   "metadata": {},
   "source": [
    "Данная лабораторная работа ориентирована на знакомство с деревьями решений с реализацией на языке программирования Python:\n",
    "\n",
    "Реализовать решение задачи классификации пользовательских данных с использованием деревьев решений. Сравнить с ранее применявшимися методами.\n",
    "Реализовать решение задачи регрессии для пользовательских данных с использованием деревьев решений. Сравнить с ранее применявшимися методами.\n",
    "Реализовать решение задачи заполнения пропусков с использованием деревьев решений. Сравнить с ранее применявшимися методами.\n",
    "Самостоятельно программно реализовать по крайней мере один из алгоритмов построения деревьев решений (ID3, C4.5, C5.0, CART)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9e95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y=load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e807d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26962a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6274165202108963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y==1)/len(y) #Процент людей с раком груди. Датасет +- сбалансированный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c36ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b1bc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': 40, 'criterion': 'entropy', 'class_weight': None}\n",
      "Лучшее качество модели: 0.9384615384615385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.63956044 0.9010989  0.93626374 0.85274725 0.92307692 0.92527473\n",
      " 0.91428571 0.91428571 0.89010989 0.8989011  0.91428571 0.91868132\n",
      " 0.82417582 0.86813187 0.8989011  0.92307692 0.90549451        nan\n",
      " 0.85714286 0.88131868 0.76703297        nan 0.78901099 0.83076923\n",
      " 0.87032967 0.91428571 0.90769231 0.8989011  0.93846154 0.88571429\n",
      " 0.78901099        nan 0.89230769 0.80659341 0.92087912 0.91648352\n",
      " 0.87912088 0.93186813 0.58901099 0.92087912 0.90769231        nan\n",
      " 0.61758242 0.90769231 0.82637363 0.92307692 0.88351648 0.81538462\n",
      " 0.8989011  0.84395604 0.88571429 0.89450549 0.88351648 0.90989011\n",
      " 0.88131868 0.88351648 0.9010989         nan 0.91648352 0.91648352\n",
      " 0.91648352 0.90769231 0.92307692 0.80879121 0.92087912 0.93846154\n",
      " 0.88791209 0.67912088 0.91428571 0.81538462 0.9032967  0.92307692\n",
      " 0.92527473        nan 0.91208791 0.8989011  0.91208791 0.92087912\n",
      " 0.89230769 0.92527473 0.91428571 0.92747253 0.88571429 0.72087912\n",
      " 0.89010989        nan        nan 0.91428571 0.92087912 0.79340659\n",
      " 0.91648352 0.92967033 0.9032967  0.91208791 0.91428571        nan\n",
      " 0.9032967  0.88351648 0.90549451 0.89010989]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 45,  50, 55, 60],\n",
    "    'min_samples_split': [1, 2, 3, 4,  5, 10, 15, 20, 25, 30 , 40],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7,8, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'class_weight': ['balanced', None],\n",
    "    #'min_impurity_decrease' : uniform(0, 0.2),\n",
    "    #'ccp_alpha' : uniform(0, 0.2)\n",
    "}\n",
    "dtree = DecisionTreeClassifier()\n",
    "random_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\", random_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad31978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model=random_search.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "print(accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5350d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'kernel': 'linear', 'gamma': 'auto', 'C': 100}\n",
      "Лучшее качество модели: 0.956043956043956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_model = SVC()\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    #'C': uniform(loc=0, scale=40),\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=svm_model, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', n_jobs=10, random_state=42)\n",
    "rand_search.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\", rand_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c551fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "model=rand_search.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "print(accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3f914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 24 is smaller than n_iter=30. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'knn__weights': 'distance', 'knn__n_neighbors': 8}\n",
      "Лучшее качество модели: 0.9736263736263737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),      \n",
    "    ('knn', KNeighborsClassifier())       \n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'knn__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25],       \n",
    "    'knn__weights': ['uniform', 'distance'],                    \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=knn_pipe, param_distributions=param_dist, cv=5, n_iter=30, scoring='accuracy',  n_jobs=10)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры:\", rand_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbbb8796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model=rand_search.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "print(accuracy_score(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a4216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y=fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cbd59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5513e9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'splitter': 'best', 'min_samples_split': 25, 'min_samples_leaf': 6, 'max_features': 'auto', 'max_depth': 20, 'criterion': 'friedman_mse'}\n",
      "Лучшее качество модели: -0.37555495939056344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.80665805 -0.39307693 -0.4310744  -0.49157751 -0.3903589  -0.38732612\n",
      " -0.40588112 -0.70724384 -0.49263972 -0.7231827  -0.56419112 -0.44419259\n",
      " -0.88413468 -0.99807698 -0.42041007 -0.56764153 -0.4129213          nan\n",
      " -1.00727343 -0.51574634 -0.43310747         nan -0.73097458 -0.51681041\n",
      " -0.75930918 -0.44550452 -0.45115216 -0.38967567 -0.77857719 -0.49186952\n",
      " -0.95142745         nan -0.38511207 -0.94423279 -0.37555496 -0.44249008\n",
      " -0.44984822 -0.60829111 -0.50172389 -0.47000686]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'criterion' : ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 45,  50, 55, 60],\n",
    "    'min_samples_split': [1, 2, 3, 4,  5, 10, 15, 20, 25, 30 , 40],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7,8, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #'min_impurity_decrease' : uniform(0, 0.2),\n",
    "    #'ccp_alpha' : uniform(0, 0.2)\n",
    "}\n",
    "dtree = DecisionTreeRegressor()\n",
    "random_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_dist,  n_iter=40, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\", random_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa5621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36688586754511826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "model=random_search.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "print(mean_squared_error(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea52129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, gamma='auto')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_model = SVR(C=1, kernel='rbf', gamma='auto')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae1f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1671454913141537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mean_squared_error(svm_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1fadbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 24 is smaller than n_iter=30. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'knn__weights': 'distance', 'knn__n_neighbors': 9}\n",
      "Лучшее качество модели: -0.4047386594377632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),      \n",
    "    ('knn', KNeighborsRegressor())       \n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'knn__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25],       \n",
    "    'knn__weights': ['uniform', 'distance'],                    \n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(estimator=knn_pipe, param_distributions=param_dist, cv=5, n_iter=30, scoring='neg_mean_squared_error',  n_jobs=10)\n",
    "rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Лучшие параметры:\", rand_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26346dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41914274251715045\n"
     ]
    }
   ],
   "source": [
    "model=rand_search.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "print(mean_squared_error(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4650d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4         NaN -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
      "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
      "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
      "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
      "441       NaN -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
      "\n",
      "           s4        s5        s6  \n",
      "0   -0.002592  0.019908 -0.017646  \n",
      "1   -0.039493 -0.068330 -0.092204  \n",
      "2   -0.002592  0.002864 -0.025930  \n",
      "3    0.034309  0.022692 -0.009362  \n",
      "4   -0.002592 -0.031991 -0.046641  \n",
      "..        ...       ...       ...  \n",
      "437 -0.002592  0.031193  0.007207  \n",
      "438  0.034309 -0.018118  0.044485  \n",
      "439 -0.011080 -0.046879  0.015491  \n",
      "440  0.026560  0.044528 -0.025930  \n",
      "441 -0.039493 -0.004220  0.003064  \n",
      "\n",
      "[442 rows x 10 columns] 0      151.0\n",
      "1       75.0\n",
      "2      141.0\n",
      "3      206.0\n",
      "4      135.0\n",
      "       ...  \n",
      "437    178.0\n",
      "438    104.0\n",
      "439    132.0\n",
      "440    220.0\n",
      "441     57.0\n",
      "Name: target, Length: 442, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "X, y=load_diabetes(return_X_y=True, as_frame=True)\n",
    "indices_to_remove = np.random.choice(X.index, 80, replace=False)\n",
    "removed_age_values = X.loc[indices_to_remove, 'age']\n",
    "X.loc[indices_to_remove, 'age'] = None\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7820726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Imputation - MSE: 0.001998376311698617, RMSE: 0.04470320247698835, MAE: 0.03674784271126715, MAPE: 1.01036488326491, SMAPE: 1.8675915528056457, WAPE: 1.0069595467635004\n",
      "KNN Imputation - MSE: 0.0020224095011194417, RMSE: 0.04497120746788373, MAE: 0.03534459912842027, MAPE: 2.4365829979431815, SMAPE: 1.2489841144426883, WAPE: 0.9685080508951717\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "data_mean = X.copy()\n",
    "data_knn = X.copy()\n",
    "\n",
    "\n",
    "mean_age = data_mean['age'].mean()\n",
    "data_mean['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "data_knn['age'] = pd.DataFrame(imputer.fit_transform(data_knn))[0]  #\n",
    "#print(data_knn['age'])\n",
    "\n",
    "true_age = removed_age_values\n",
    "\n",
    "\n",
    "\n",
    "filled_mean = data_mean.loc[indices_to_remove, 'age']\n",
    "filled_knn = data_knn.loc[indices_to_remove, 'age']\n",
    "\n",
    "\n",
    "mse_mean = mean_squared_error(true_age, filled_mean)\n",
    "rmse_mean = math.sqrt(mse_mean)\n",
    "mae_mean = mean_absolute_error(true_age, filled_mean)\n",
    "mape_mean = np.mean(np.abs((true_age - filled_mean) / true_age)) \n",
    "smape_mean =  np.mean(2 * np.abs(filled_mean - true_age) / (np.abs(filled_mean) + np.abs(true_age)))\n",
    "wape_mean = np.sum(np.abs(filled_mean - true_age)) / np.sum(np.abs(true_age))\n",
    "\n",
    "\n",
    "mse_knn = mean_squared_error(true_age, filled_knn)\n",
    "rmse_knn = math.sqrt(mse_knn)\n",
    "mae_knn = mean_absolute_error(true_age, filled_knn)\n",
    "mape_knn = np.mean(np.abs((true_age - filled_knn) / true_age)) \n",
    "smape_knn = np.mean(2 * np.abs(filled_knn - true_age) / (np.abs(filled_knn) + np.abs(true_age)))\n",
    "wape_knn = np.sum(np.abs(filled_knn - true_age)) / np.sum(np.abs(true_age))\n",
    "\n",
    "\n",
    "print(f\"Mean Imputation - MSE: {mse_mean}, RMSE: {rmse_mean}, MAE: {mae_mean}, MAPE: {mape_mean}, SMAPE: {smape_mean}, WAPE: {wape_mean}\")\n",
    "print(f\"KNN Imputation - MSE: {mse_knn}, RMSE: {rmse_knn}, MAE: {mae_knn}, MAPE: {mape_knn}, SMAPE: {smape_knn}, WAPE: {wape_knn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df03c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 40, 'criterion': 'absolute_error'}\n",
      "Лучшее качество модели: -2.3944663686137243e-05\n",
      "0.0040135262638679005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 178, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-1.79507820e-03 -1.15063698e-03 -1.08673235e-03 -1.05109222e-03\n",
      " -5.63136418e-05 -2.39446637e-05 -1.32428938e-04 -9.11879123e-04\n",
      " -1.47730466e-03 -1.24816102e-03 -5.56672022e-04 -3.27394564e-04\n",
      " -1.93482671e-03             nan -7.27938190e-04             nan\n",
      " -1.30746495e-03             nan -1.99748573e-03 -9.09916373e-04\n",
      " -1.22787630e-04             nan -1.83463795e-03 -9.70500671e-04\n",
      "             nan -4.69760455e-04 -9.76308449e-04 -6.53441476e-04\n",
      "             nan -9.68467376e-04 -2.18920572e-03             nan\n",
      " -7.47588740e-04 -1.63862278e-03 -2.67356976e-05 -1.09845520e-04\n",
      " -9.74413678e-04 -8.53577037e-04 -1.06900178e-03 -1.14757451e-03]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df=X\n",
    "known_age = df[df['age'].notna()]\n",
    "unknown_age = df[df['age'].isna()]\n",
    "y_train=known_age['age']\n",
    "X_train=known_age.drop(['age'], axis=1)\n",
    "\n",
    "y_test=unknown_age['age']\n",
    "X_test=unknown_age.drop(['age'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'criterion' : ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 45,  50, 55, 60],\n",
    "    'min_samples_split': [1, 2, 3, 4,  5, 10, 15, 20, 25, 30 , 40],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7,8, 10, 15, 20, 25, 30, 35, 40],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #'min_impurity_decrease' : uniform(0, 0.2),\n",
    "    #'ccp_alpha' : uniform(0, 0.2)\n",
    "}\n",
    "dtree = DecisionTreeRegressor()\n",
    "random_search = RandomizedSearchCV(estimator=dtree, param_distributions=param_dist,  n_iter=40, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Лучшие параметры:\", random_search.best_params_)\n",
    "print(\"Лучшее качество модели:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "print(mean_squared_error(removed_age_values, random_search.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c3b0224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.4.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\anaconda3\\lib\\site-packages (from category_encoders) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2021.3)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.4)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b87cdc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting deepdiff\n",
      "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script deep.exe is installed in 'C:\\Users\\Алекхаил\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ordered-set<4.2.0,>=4.0.2\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: ordered-set, deepdiff\n",
      "Successfully installed deepdiff-6.7.1 ordered-set-4.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install deepdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5915b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from array import array\n",
    "from copy import deepcopy\n",
    "from deepdiff import DeepDiff\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from category_encoders import *\n",
    "from typing import List, Union, Tuple\n",
    "import pprint\n",
    "def compute_impurity (target_vector: np.array, criterion: str = 'gini') -> float:\n",
    "    unique_vals, probas=np.unique(target_vector, return_counts=True)\n",
    "    probas=probas/np.sum(probas)\n",
    "    if criterion=='gini' :\n",
    "        return probas@(1-probas)\n",
    "    else :\n",
    "        return -np.sum([p*np.log2(p) for p in probas if p>0])\n",
    "\n",
    "def compute_criterion(target_vector: np.array, feature_vector: np.array, threshold: float, criterion: str = 'gini') -> float:\n",
    "    assert criterion in ['gini', 'entropy'], \"Критерий может быть только 'gini' или 'entropy'!\"\n",
    "\n",
    "    pass\n",
    "    if  len(np.unique(feature_vector))==1 :\n",
    "        return 0\n",
    "    n=len(target_vector)\n",
    "    n_left=sum(feature_vector<=threshold)\n",
    "    n_right=sum(feature_vector>threshold)\n",
    "    H_R=compute_impurity(target_vector=target_vector, criterion=criterion)\n",
    "    H_Rl=compute_impurity(target_vector=target_vector[feature_vector<=threshold], criterion=criterion)\n",
    "    H_Rr=compute_impurity(target_vector=target_vector[feature_vector>threshold], criterion=criterion)\n",
    "    Q=H_R-n_left/n*H_Rl-n_right/n*H_Rr\n",
    "    return Q\n",
    "\n",
    "def find_best_split(feature_vector: np.ndarray, target_vector: np.ndarray, criterion: str = 'gini') -> Tuple:\n",
    "    unq_vals = np.sort(np.unique(feature_vector))\n",
    "\n",
    "    if len(unq_vals) == 1:\n",
    "        return None, None, None, 0\n",
    "\n",
    "    pass\n",
    "    thresholds=(unq_vals[1:]+unq_vals[:-1])/2\n",
    "    criterion_vals=np.array([compute_criterion(target_vector=target_vector, feature_vector=feature_vector, threshold=t, criterion=criterion) for t in thresholds])\n",
    "    threshold_best=thresholds[0]\n",
    "    criterion_best=criterion_vals[0]\n",
    "    for t in range(len(criterion_vals)) :\n",
    "        if criterion_vals[t]>criterion_best :\n",
    "            criterion_best=criterion_vals[t]\n",
    "            threshold_best=thresholds[t]\n",
    "    return thresholds, criterion_vals, threshold_best, criterion_best\n",
    "\n",
    "\n",
    "class DecisionTree(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_types: list,\n",
    "            criterion: str = 'gini',\n",
    "            max_depth: int = None,\n",
    "            min_samples_split: int = None,\n",
    "    ):\n",
    "\n",
    "        self._feature_types = feature_types\n",
    "        self._tree = {}\n",
    "        # Сюда будут сохраняться обученные таргет энкодеры категориальных фичей\n",
    "        self.target_encodings = {} # Dict[int<номер категориальной фичи>, category_encoders.target_encoder.TargetEncoder]\n",
    "        self._criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self.cols=[]\n",
    "        self.enc=1\n",
    "\n",
    "    def _fit_node(self, sub_X: np.ndarray, sub_y: np.ndarray, node: dict, level: int):\n",
    "        level+=1\n",
    "\n",
    "        if level==self.max_depth or len(sub_X)<self._min_samples_split or len(np.unique(sub_y))==1 :\n",
    "            \n",
    "            dic={}\n",
    "            unique_vals=self.classes\n",
    "            probas=[0 for i in range(len(unique_vals))]\n",
    "            for k in range(len(unique_vals)) :\n",
    "                for r in range(len(sub_y)) :\n",
    "                    if sub_y[r]==unique_vals[k] :\n",
    "                        probas[k]+=1\n",
    "            dic={'type': 'terminal', 'classes_distribution': np.array(probas)}\n",
    "            #dic.update({'type': 'terminal'})\n",
    "            #dic.update({'classes_distribution': probas}) \n",
    "        else :\n",
    "            \n",
    "            dic={}\n",
    "            indicator=0\n",
    "            for i in range(len(self._feature_types)) :\n",
    "                feature_vector=sub_X[:, i]\n",
    "                if len(np.unique(feature_vector))!=1 :\n",
    "                    ans=find_best_split(feature_vector=feature_vector, target_vector=sub_y, criterion=self._criterion)\n",
    "                    thresholds=ans[0]\n",
    "                    criterion_vals=ans[1]\n",
    "                    for j in range(len(thresholds)) :\n",
    "                        if indicator==0 :\n",
    "                            threshold_best= thresholds[j]\n",
    "                            criterion_best=criterion_vals[j]\n",
    "                            feature_best=i\n",
    "                            indicator=1 \n",
    "                        else :\n",
    "                            if criterion_vals[j]>criterion_best :\n",
    "                                threshold_best= thresholds[j]\n",
    "                                criterion_best=criterion_vals[j]\n",
    "                                feature_best=i\n",
    "            \n",
    "            feature_vector=sub_X[:, feature_best]\n",
    "            if self._feature_types[feature_best]=='categorical' :\n",
    "                \n",
    "                dic={'type': 'nonterminal', \n",
    "                     'feature_type':  'categorical', \n",
    "                     'feature_number': feature_best, \n",
    "                     'threshold' : threshold_best,\n",
    "                     'left_child': self._fit_node(sub_X=sub_X[feature_vector<=threshold_best], sub_y=sub_y[feature_vector<=threshold_best], node=self._tree, level=level),\n",
    "                     'right_child': self._fit_node(sub_X=sub_X[feature_vector>threshold_best], sub_y=sub_y[feature_vector>threshold_best], node=self._tree, level=level)\n",
    "                     }\n",
    "                \n",
    "            else :\n",
    "                \n",
    "                dic={'type': 'nonterminal', \n",
    "                     'feature_type':  'real', \n",
    "                     'feature_number': feature_best, \n",
    "                     'threshold' : threshold_best,\n",
    "                     'left_child':  self._fit_node(sub_X=sub_X[feature_vector<=threshold_best], sub_y=sub_y[feature_vector<=threshold_best], node=self._tree, level=level),\n",
    "                     'right_child': self._fit_node(sub_X=sub_X[feature_vector>threshold_best], sub_y=sub_y[feature_vector>threshold_best], node=self._tree, level=level)\n",
    "                     }\n",
    "            #dic.update({'feature_number': feature_best})\n",
    "            #dic.update({'threshold' : threshold_best })\n",
    "           # feature_vector=sub_X[:, feature_best]\n",
    "           # dic.update({'left_child': self._fit_node(sub_X=sub_X[feature_vector<=threshold_best], sub_y=sub_y[feature_vector<=threshold_best], node=self._tree, level=level)})\n",
    "           # dic.update({'right_child': self._fit_node(sub_X=sub_X[feature_vector>threshold_best], sub_y=sub_y[feature_vector>threshold_best], node=self._tree, level=level)})\n",
    "        return dic\n",
    "\n",
    "    def _predict_proba_object(self, x: np.array, node: dict) -> Union[List, np.ndarray]:\n",
    "\n",
    "        #pprint.pprint(node['right_child'])\n",
    "        if  node['type']=='terminal' :\n",
    "            ans=node['classes_distribution']/np.sum(node['classes_distribution'])\n",
    "            return ans\n",
    "        else :\n",
    "            if node['threshold']>x[node['feature_number']] :\n",
    "                return self._predict_proba_object(x=x, node=node['left_child'])\n",
    "            else :\n",
    "                return self._predict_proba_object(x=x, node=node['right_child'])\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "\n",
    "        assert len(set(y)) > 1, 'Таргет должен содержать более одного класса!'\n",
    "        \n",
    "        X=pd.DataFrame(X)\n",
    "        y=pd.DataFrame(y)\n",
    "        \n",
    "        \n",
    "        for i in range(len(self._feature_types)) :\n",
    "            if self._feature_types[i]==\"categorical\" :\n",
    "                self.cols.append(i)\n",
    "        #print(cols)\n",
    "        if len(self.cols)!=0 :\n",
    "            self.enc=TargetEncoder(cols=self.cols).fit(X, y)\n",
    "            #print(self.enc)\n",
    "            #print(self.enc.mapping)\n",
    "            X=self.enc.transform(X)\n",
    "        X=X.to_numpy()\n",
    "        y=y.to_numpy()\n",
    "        self.classes=np.unique(y)\n",
    "        self.classes=np.sort(self.classes)\n",
    "        if self._min_samples_split==None :\n",
    "            self._min_samples_split=2\n",
    "        self._tree =self._fit_node(sub_X=X, sub_y=y, node=self._tree, level=0)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        assert self._tree != {}, \"Cначала обучите модель!\"\n",
    "        if len(self.cols)!=0 :\n",
    "            X=pd.DataFrame(X)\n",
    "            X=self.enc.transform(X)\n",
    "            X=X.to_numpy()\n",
    "       \n",
    "        predicted = []\n",
    "        for x in X:\n",
    "            a=self._predict_proba_object(x, self._tree)\n",
    "            predicted.append(a)\n",
    "        return np.array(predicted)\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return np.argmax(self.predict_proba(X=X), axis=1).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc6e0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y=load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3d8379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37c97446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631578947368421  criterion=  gini  max_depth=  1  min_samples_split= 10\n",
      "0.631578947368421  criterion=  gini  max_depth=  1  min_samples_split= 15\n",
      "0.9210526315789473  criterion=  gini  max_depth=  2  min_samples_split= 10\n",
      "0.9210526315789473  criterion=  gini  max_depth=  2  min_samples_split= 15\n",
      "0.8947368421052632  criterion=  gini  max_depth=  3  min_samples_split= 10\n",
      "0.8947368421052632  criterion=  gini  max_depth=  3  min_samples_split= 15\n",
      "0.9385964912280702  criterion=  gini  max_depth=  4  min_samples_split= 10\n",
      "0.9385964912280702  criterion=  gini  max_depth=  4  min_samples_split= 15\n",
      "0.9122807017543859  criterion=  gini  max_depth=  6  min_samples_split= 10\n",
      "0.9385964912280702  criterion=  gini  max_depth=  6  min_samples_split= 15\n",
      "0.9122807017543859  criterion=  gini  max_depth=  7  min_samples_split= 10\n",
      "0.9385964912280702  criterion=  gini  max_depth=  7  min_samples_split= 15\n",
      "0.631578947368421  criterion=  entropy  max_depth=  1  min_samples_split= 10\n",
      "0.631578947368421  criterion=  entropy  max_depth=  1  min_samples_split= 15\n",
      "0.9210526315789473  criterion=  entropy  max_depth=  2  min_samples_split= 10\n",
      "0.9210526315789473  criterion=  entropy  max_depth=  2  min_samples_split= 15\n",
      "0.8947368421052632  criterion=  entropy  max_depth=  3  min_samples_split= 10\n",
      "0.8947368421052632  criterion=  entropy  max_depth=  3  min_samples_split= 15\n",
      "0.9473684210526315  criterion=  entropy  max_depth=  4  min_samples_split= 10\n",
      "0.9473684210526315  criterion=  entropy  max_depth=  4  min_samples_split= 15\n",
      "0.9210526315789473  criterion=  entropy  max_depth=  6  min_samples_split= 10\n",
      "0.9298245614035088  criterion=  entropy  max_depth=  6  min_samples_split= 15\n",
      "0.9210526315789473  criterion=  entropy  max_depth=  7  min_samples_split= 10\n",
      "0.9298245614035088  criterion=  entropy  max_depth=  7  min_samples_split= 15\n"
     ]
    }
   ],
   "source": [
    "max_depth=[1, 2,3 ,4 ,6, 7]\n",
    "min_samples_split=[10, 15]\n",
    "criterion=['gini', 'entropy']\n",
    "feature_types=['real']*30\n",
    "for x in criterion :\n",
    "    for depth in max_depth:\n",
    "        for split in  min_samples_split :\n",
    "            dtree = DecisionTree(feature_types=feature_types, criterion=x, max_depth=depth, min_samples_split=split)\n",
    "            dtree.fit(np.array(X_train), np.array(y_train))\n",
    "            print(accuracy_score(dtree.predict(np.array(X_test)), y_test), ' criterion= ', x, ' max_depth= ', depth, ' min_samples_split=', split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a92847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c52ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
